<!DOCTYPE html>

<!--
  portfolYOU Jekyll theme by Youssef Raafat
  Free for personal and commercial use under the MIT license
  https://github.com/YoussefRaafatNasry/portfolYOU
-->

<html lang="en" class="h-100">

<head>

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="I turn coffee :coffee: into code, use tabs over spaces and never broke production.">

  <title>Neetha Reddy</title>
  <link rel="shortcut icon" type="image/x-icon" href="/assets/favicon.ico">

  <!-- Font Awesome CDN -->
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.10.0/css/all.css">

  <!-- Bootstrap CSS CDN -->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css">

  <!-- Animate CSS CDN -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.7.0/animate.css" type="text/css"/>
  
  <!-- Custom CSS -->
  <link rel="stylesheet" href="/assets/css/style.css" type="text/css">

</head>


<body class="d-flex flex-column h-100">

  <main class="flex-shrink-0 container mt-5">
  <nav class="navbar navbar-expand-lg navbar-light">

  <a class="navbar-brand" href="/"><h5><b>Neetha Reddy</b></h5></a>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  <div class="collapse navbar-collapse" id="navbarNavAltMarkup">
    <div class="navbar-nav ml-auto">
<a class="nav-item nav-link " href="/projects/">Projects</a>

      <a class="nav-item nav-link active" href="/blog/">Blog</a>

      <a class="nav-item nav-link " href="/about/">About</a>

      

    </div>
  </div>

</nav>
  <div class="col-lg-10 mx-auto mt-5 post">
  <h1><b>Ethical dilemmma of self-driving cars</b></h1>

<p class="post-metadata text-muted">
  21 July 2020 -  
  <b>4 mins read time</b>

  <br>Tags: 
    
    <a class="text-decoration-none no-underline" href="/blog/tags#ai">
      <span class="tag badge badge-pill text-primary border border-primary">AI</span>
    </a>
    
    <a class="text-decoration-none no-underline" href="/blog/tags#ml">
      <span class="tag badge badge-pill text-primary border border-primary">ML</span>
    </a>
    
    <a class="text-decoration-none no-underline" href="/blog/tags#technology">
      <span class="tag badge badge-pill text-primary border border-primary">Technology</span>
    </a>
    </p>

<p><img src="https://www.roboticsbusinessreview.com/wp-content/uploads/2019/10/AdobeStock_224332680-1024x682.jpeg" alt=""></p>

<p>Self-driving technology is slowly making its way into the vehicular industries, with self-driving cars from Tesla and Cadillac already cruising the streets. According to a survey conducted by WHO in 2016, about 1.35 million people die in road accidents on the yearly and about 90% of these accidents were attributed to human error. Self-driving technology seems like the perfect solution to this problem due to its ability to minimize human error. It also aids in easing traffic and increasing fuel efficiency. But this technology comes with its own set of challenges.</p>

<p><img src="https://mir-s3-cdn-cf.behance.net/project_modules/disp/2177dc31769985.565f9a4b13c8d.gif" alt=""></p>

<p>Let us consider a scenario in which we are travelling in a self-driving car on a highway when all of a sudden a large object falls off the truck moving in front of you. We are boxed in from all the sides and a collision seems unavoidable. Now the car has to make a decision; to either swerve to hit the SUV on the right or hit the motorcyclist on the left or let the heavy object hit you. We are sacrificing ourselves and causing others no harm if we let the object hit us, minimizing danger to human life by swerving right since SUVs have a high passenger safety rating or severely injure the motorcyclist if we swerve left. When a human is driving and encounters this scenario, they are given some leniency because any decision that was taken at the time would be a panicked response to the situation with no mal intentions. Machines, on the other hand, are not given the treatment because they are instructed by the programmers well in advance, which might come across as premeditated homicide.</p>

<p><img src="https://mir-s3-cdn-cf.behance.net/project_modules/disp/58204931769985.565f9a48baa3d.gif" alt=""></p>

<p>Now consider a motorcyclist is wearing a helmet instead of the SUV on the right while the one on the left is not wearing one. Here if we go with the principle of minimizing harm, the car should swerve right and hit the motorcyclist wearing the helmet. This is penalising them for obeying traffic rules. If we instead choose to swerve left, we will cause greater injuries to the motorcyclist on the left which goes against our principle of minimizing harm. Such decision making by the machine might sometimes compromise our safety in the name of minimizing harm.</p>

<p>People think ethically in principle, but in practice, they behave more selfishly. So between a car which would always save as many lives as it can and a car saving us at any cost, many people prefer the latter. Ironically, the same people will expect other people to buy cars in the first type. By making the individually rational choice of prioritizing their safety, they may collectively be diminishing the common good i.e., minimizing total harm.</p>

<p>I thought that the evolutionary approach to training these models was the best way to go forward to solving these problems. Similar to how we raise children. We can tell them a stove is hot, but we cannot innately protect them from everything hot. That is learned through self-exploration and correcting themselves. The same approach can be used for machines. This machine training through reinforcement (Reinforcement learning)can be monitored through a checkpoint system. We input several scenarios to the system and then giving appropriate feedback for its solutions, enabling it ‘to learn’ and correct its ‘mistakes’. Collect data from car manufacturers regarding car crashes and mistakes generally committed by the drivers which can be avoided.</p>

<p><img src="https://media.nature.com/lw800/magazine-assets/d41586-018-07135-0/d41586-018-07135-0_16219594.png" alt=""></p>

<p>There are several other challenges. Moral choices are not universal; they differ from country to country. This might lead to bias based on gender, race, age, job, the economic prosperity of the country, etc to name a few. In cases of unavoidable death, countries where economic inequality is high like in Columbia, people prefer to kill the homeless in opposed to the executives; people in countries with strong government institutions would rather ‘punish’ those who do not follow traffic rules, etc. Here, in India, the killing of animals such as cows is unacceptable, no matter the scenario. We have a long way to go to solve the ethical dilemmas which come with self-driving technology. Almost every solution has its drawbacks and trade-offs. We can only attempt to reduce the number of problems. This can be achieved only through research and asking the right questions.</p>

<p>References:<br>
-<a href="https://www.youtube.com/watch?v=ixIoDYVfKA0"> TED talk on the ethical dilemma od self-driving cars </a><br>
-<a href="https://www.theglobeandmail.com/globe-drive/culture/technology/the-ethical-dilemmas-of-self-drivingcars/article37803470/">https://www.theglobeandmail.com/globe-drive/culture/technology/the-ethical-dilemmas-of-self-drivingcars/article37803470/</a><br>
-<a href="https://www.theverge.com/2018/10/24/18013392/self-driving-car-ethics-dilemma-mit-study-moral-machine-results">https://www.theverge.com/2018/10/24/18013392/self-driving-car-ethics-dilemma-mit-study-moral-machine-results</a><br></p>



</div>
  </main>

  <footer class="mt-auto py-3 text-center">

  <small class="text-muted mb-2">
    <i class="fas fa-code"></i> with <i class="fas fa-heart"></i>
    by <strong>Neetha Reddy</strong>
  </small>

  <div class="container-fluid justify-content-center">
<a class="social mx-1" href="mailto:neetha.reddy@iiitb.org" style="color: #6c757d" onmouseover="this.style.color='#db4437'" onmouseout="this.style.color='#6c757d'">
      <i class="fas fa-envelope fa-1x"></i>
    </a><a class="social mx-1" href="https://www.github.com/purplesmurf45" style="color: #6c757d" onmouseover="this.style.color='#333333'" onmouseout="this.style.color='#6c757d'">
      <i class="fab fa-github fa-1x"></i>
    </a><a class="social mx-1" href="https://www.linkedin.com/in/neetha-reddy" style="color: #6c757d" onmouseover="this.style.color='#007bb5'" onmouseout="this.style.color='#6c757d'">
      <i class="fab fa-linkedin-in fa-1x"></i>
    </a><a class="social mx-1" href="https://www.twitter.com/NyxReddy" style="color: #6c757d" onmouseover="this.style.color='#1da1f2'" onmouseout="this.style.color='#6c757d'">
      <i class="fab fa-twitter fa-1x"></i>
    </a>

</div>
<small id="attribution">
    theme <a href="https://github.com/YoussefRaafatNasry/portfolYOU">portfolYOU</a>
  </small>
  
</footer>
  
  <!-- GitHub Buttons -->
<script async defer src="https://buttons.github.io/buttons.js"></script>

<!-- jQuery CDN -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

<!-- Popper.js CDN -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js"></script>

<!-- Bootstrap JS CDN -->
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>

<!-- wow.js CDN & Activation -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/wow/1.1.2/wow.js"></script>
<script> new WOW().init(); </script>

<!-- Initialize all tooltips -->
<script>
$(function () {
    $('[data-toggle="tooltip"]').tooltip()
})
</script>

</body>

</html>